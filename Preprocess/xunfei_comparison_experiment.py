#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç§‘å¤§è®¯é£è¯­éŸ³è¯„æµ‹APIæ•æ„Ÿæ€§å¯¹æ¯”å®éªŒ
åˆ›å»ºé’ˆå¯¹ä¸åŒè¯„æµ‹ç»´åº¦çš„ä½è´¨é‡éŸ³é¢‘æ ·æœ¬ï¼ŒéªŒè¯APIçš„åŒºåˆ†èƒ½åŠ›

éœ€è¦å®‰è£…çš„ä¾èµ–:
pip install librosa soundfile pydub numpy

ä½¿ç”¨æ–¹æ³•:
python xunfei_comparison_experiment.py
"""

import os
import shutil
import random
import numpy as np
import librosa
import soundfile as sf
from pydub import AudioSegment
import statistics
from typing import Dict, List, Optional
import warnings
warnings.filterwarnings("ignore")

# å¯¼å…¥ä½ çš„è¯­éŸ³è¯„æµ‹å™¨ (éœ€è¦å°†speech_quality_evaluator.pyæ”¾åœ¨åŒä¸€ç›®å½•)
try:
    from speech_quality_evaluator import SpeechQualityEvaluator
except ImportError:
    print("âŒ è¯·ç¡®ä¿ speech_quality_evaluator.py æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    exit(1)


class XunfeiTargetedDegrader:
    """é’ˆå¯¹ç§‘å¤§è®¯é£è¯„æµ‹ç»´åº¦çš„éŸ³é¢‘é™è´¨å™¨"""
    
    def __init__(self):
        # ç›®æ ‡é™è´¨ç¨‹åº¦ï¼ˆç›¸æ¯”baselineï¼‰
        self.target_drops = {
            'fluency_drop': (15, 25),      # æµåˆ©åº¦ä¸‹é™15-25åˆ†
            'tone_drop': (10, 20),         # å£°è°ƒå‡†ç¡®åº¦ä¸‹é™10-20åˆ†  
            'phone_drop': (10, 20),        # éŸ³ç´ å‡†ç¡®åº¦ä¸‹é™10-20åˆ†
            'total_drop': (15, 30),        # æ€»åˆ†ä¸‹é™15-30åˆ†
            'stability_increase': (5, 15)   # ç¨³å®šæ€§å˜å·®(æ ‡å‡†å·®å¢åŠ 5-15)
        }
        
        # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶ç›®å½•å­˜åœ¨
        self.temp_dir = "temp_audio_processing"
        os.makedirs(self.temp_dir, exist_ok=True)
    
    def create_poor_samples_by_dimension(self, good_audio_folder, output_folder):
        """æŒ‰ç»´åº¦åˆ›å»ºä½è´¨é‡æ ·æœ¬"""
        
        print("ğŸ”§ å¼€å§‹åˆ›å»ºé™è´¨éŸ³é¢‘æ ·æœ¬...")
        os.makedirs(output_folder, exist_ok=True)
        
        # ä¸ºæ¯ä¸ªç»´åº¦åˆ›å»ºä¸“é—¨çš„ä½è´¨é‡æ ·æœ¬
        dimensions = {
            'poor_fluency': self.degrade_fluency,
            'poor_tone': self.degrade_tone_accuracy, 
            'poor_phone': self.degrade_phone_accuracy,
            'poor_stability': self.degrade_stability,
            'poor_overall': self.degrade_overall
        }
        
        audio_files = [f for f in os.listdir(good_audio_folder) if f.endswith('.mp3')]
        
        if not audio_files:
            print(f"âŒ åœ¨ {good_audio_folder} ä¸­æœªæ‰¾åˆ°MP3æ–‡ä»¶")
            return
        
        for dim_name, degrade_func in dimensions.items():
            print(f"   ğŸ“ å¤„ç† {dim_name}...")
            dim_folder = os.path.join(output_folder, dim_name, "audiosample")
            os.makedirs(dim_folder, exist_ok=True)
            
            success_count = 0
            for audio_file in audio_files:
                try:
                    input_path = os.path.join(good_audio_folder, audio_file)
                    output_path = os.path.join(dim_folder, audio_file)
                    degrade_func(input_path, output_path)
                    success_count += 1
                except Exception as e:
                    print(f"      âš ï¸ å¤„ç† {audio_file} å¤±è´¥: {e}")
            
            print(f"   âœ… {dim_name}: {success_count}/{len(audio_files)} ä¸ªæ–‡ä»¶å¤„ç†æˆåŠŸ")
    
    def degrade_fluency(self, input_path: str, output_path: str):
        """ä¸“é—¨é™ä½æµåˆ©åº¦ - æ·»åŠ åœé¡¿å’Œè¯­é€Ÿå˜åŒ–"""
        try:
            audio = AudioSegment.from_file(input_path)
            
            # 1. æ·»åŠ ä¸è‡ªç„¶åœé¡¿
            segments = []
            chunk_duration = random.randint(800, 1500)  # 0.8-1.5ç§’åˆ‡å—
            pause_duration = random.randint(200, 600)   # 200-600msåœé¡¿
            
            for i in range(0, len(audio), chunk_duration):
                chunk = audio[i:i+chunk_duration]
                segments.append(chunk)
                
                # 30%æ¦‚ç‡æ·»åŠ åœé¡¿
                if random.random() < 0.3 and i + chunk_duration < len(audio):
                    silence = AudioSegment.silent(duration=pause_duration)
                    segments.append(silence)
            
            choppy_audio = sum(segments) if segments else audio
            
            # 2. éšæœºæ”¹å˜è¯­é€Ÿ
            speed_variations = [0.7, 0.8, 1.3, 1.4]  # æ˜æ˜¾çš„è¯­é€Ÿå˜åŒ–
            speed_factor = random.choice(speed_variations)
            
            # é€šè¿‡æ”¹å˜æ’­æ”¾é€Ÿåº¦å®ç°è¯­é€Ÿå˜åŒ–
            choppy_audio = choppy_audio.speedup(playback_speed=speed_factor)
            
            # 3. å¯¼å‡º
            choppy_audio.export(output_path, format="mp3", bitrate="128k")
            
        except Exception as e:
            print(f"      é™è´¨æµåˆ©åº¦å¤±è´¥ {input_path}: {e}")
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œå¤åˆ¶åŸæ–‡ä»¶
            shutil.copy2(input_path, output_path)
    
    def degrade_tone_accuracy(self, input_path: str, output_path: str):
        """ä¸“é—¨é™ä½å£°è°ƒå‡†ç¡®åº¦ - éŸ³è°ƒå˜åŒ–å’Œé¢¤éŸ³"""
        temp_wav = os.path.join(self.temp_dir, f"temp_tone_{random.randint(1000,9999)}.wav")
        
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(input_path, sr=16000)
            
            # 1. éšæœºéŸ³è°ƒåç§» (æ›´å¤§çš„åç§»)
            pitch_shift_steps = random.uniform(-4, 4)  # Â±4åŠéŸ³åç§»
            y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch_shift_steps)
            
            # 2. æ·»åŠ éŸ³è°ƒæŠ–åŠ¨/é¢¤éŸ³
            tremolo_rate = random.uniform(2.0, 5.0)  # é¢¤éŸ³é¢‘ç‡ 2-5Hz
            tremolo_depth = random.uniform(0.2, 0.4)  # é¢¤éŸ³æ·±åº¦
            tremolo = np.sin(2 * np.pi * tremolo_rate * np.arange(len(y_shifted)) / sr)
            y_tremolo = y_shifted * (1 + tremolo_depth * tremolo)
            
            # 3. è½»å¾®æ—¶é—´æ‹‰ä¼¸
            stretch_factor = random.uniform(0.95, 1.05)
            y_stretched = librosa.effects.time_stretch(y_tremolo, rate=stretch_factor)
            
            # 4. ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´å¹¶ä¿å­˜
            y_final = np.clip(y_stretched, -0.95, 0.95)
            sf.write(temp_wav, y_final, sr)
            
            # è½¬æ¢ä¸ºmp3
            audio = AudioSegment.from_wav(temp_wav)
            audio.export(output_path, format="mp3", bitrate="128k")
            
        except Exception as e:
            print(f"      é™è´¨å£°è°ƒå¤±è´¥ {input_path}: {e}")
            shutil.copy2(input_path, output_path)
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_wav):
                os.remove(temp_wav)
    
    def degrade_phone_accuracy(self, input_path: str, output_path: str):
        """ä¸“é—¨é™ä½éŸ³ç´ å‡†ç¡®åº¦ - æ¨¡ç³Šå‘éŸ³å’Œé¢‘ç‡å¤±çœŸ"""
        temp_wav = os.path.join(self.temp_dir, f"temp_phone_{random.randint(1000,9999)}.wav")
        
        try:
            y, sr = librosa.load(input_path, sr=16000)
            
            # 1. æ·»åŠ é«˜æ–¯å™ªéŸ³ (æ¨¡æ‹Ÿä¸æ¸…æ™°å‘éŸ³)
            noise_factor = random.uniform(0.03, 0.08)
            noise = np.random.normal(0, noise_factor, y.shape)
            y_noisy = y + noise
            
            # 2. é¢‘ç‡åŸŸå¤„ç† - æ¨¡æ‹Ÿå‘éŸ³ä¸å‡†
            fft = np.fft.fft(y_noisy)
            freq_bins = np.fft.fftfreq(len(fft), 1/sr)
            
            # éšæœºè¡°å‡é‡è¦çš„è¯­éŸ³é¢‘ç‡æˆåˆ†
            critical_freqs = [1000, 2000, 3000, 4000]  # é‡è¦çš„è¯­éŸ³é¢‘ç‡
            target_freq = random.choice(critical_freqs)
            bandwidth = random.uniform(300, 700)
            
            # åˆ›å»ºè¡°å‡æ©ç 
            mask = np.abs(freq_bins - target_freq) < bandwidth
            attenuation = random.uniform(0.2, 0.5)  # è¡°å‡åˆ°20-50%
            fft[mask] *= attenuation
            
            # åŒæ—¶è¡°å‡è´Ÿé¢‘ç‡éƒ¨åˆ†
            mask_neg = np.abs(freq_bins + target_freq) < bandwidth
            fft[mask_neg] *= attenuation
            
            y_filtered = np.real(np.fft.ifft(fft))
            
            # 3. æ·»åŠ è½»å¾®éçº¿æ€§å¤±çœŸ
            distortion_level = random.uniform(1.2, 1.8)
            y_distorted = np.tanh(y_filtered * distortion_level) * 0.8
            
            # 4. è½»å¾®ä½é€šæ»¤æ³¢ (æ¨¡æ‹Ÿå£éŸ³)
            from scipy import signal
            nyquist = sr / 2
            cutoff_freq = random.uniform(3500, 6000)  # æˆªæ­¢é¢‘ç‡
            sos = signal.butter(4, cutoff_freq/nyquist, btype='low', output='sos')
            y_lowpass = signal.sosfilt(sos, y_distorted)
            
            # ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
            y_final = np.clip(y_lowpass, -0.95, 0.95)
            sf.write(temp_wav, y_final, sr)
            
            # è½¬æ¢ä¸ºmp3
            audio = AudioSegment.from_wav(temp_wav)
            audio.export(output_path, format="mp3", bitrate="128k")
            
        except Exception as e:
            print(f"      é™è´¨éŸ³ç´ å¤±è´¥ {input_path}: {e}")
            # å¦‚æœscipyä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
            try:
                y, sr = librosa.load(input_path, sr=16000)
                noise = np.random.normal(0, 0.05, y.shape)
                y_noisy = y + noise
                y_final = np.clip(y_noisy, -0.95, 0.95)
                sf.write(temp_wav, y_final, sr)
                audio = AudioSegment.from_wav(temp_wav)
                audio.export(output_path, format="mp3", bitrate="128k")
            except:
                shutil.copy2(input_path, output_path)
        finally:
            if os.path.exists(temp_wav):
                os.remove(temp_wav)
    
    def degrade_stability(self, input_path: str, output_path: str):
        """ä¸“é—¨é™ä½ç¨³å®šæ€§ - è®©æ¯ä¸ªç‰‡æ®µæœ‰ä¸åŒç¨‹åº¦é—®é¢˜"""
        try:
            audio = AudioSegment.from_file(input_path)
            
            # ä¸ºè¿™ä¸ªç‰¹å®šæ–‡ä»¶éšæœºé€‰æ‹©é—®é¢˜ä¸¥é‡ç¨‹åº¦
            problem_levels = ['light', 'medium', 'severe']
            # å¢åŠ severeçš„æ¦‚ç‡ä»¥ç¡®ä¿æ›´å¤§çš„ç¨³å®šæ€§å·®å¼‚
            weights = [0.2, 0.3, 0.5]
            problem_severity = random.choices(problem_levels, weights=weights)[0]
            
            if problem_severity == 'light':
                # è½»å¾®é—®é¢˜ï¼šå°å¹…éŸ³é‡å˜åŒ–
                volume_change = random.uniform(-4, 4)  # Â±4dB
                audio = audio + volume_change
                
            elif problem_severity == 'medium': 
                # ä¸­ç­‰é—®é¢˜ï¼šè¯­é€Ÿ+éŸ³é‡ç»„åˆ
                speed_factor = random.choice([0.75, 0.85, 1.25, 1.35])
                audio = audio.speedup(playback_speed=speed_factor)
                
                volume_change = random.uniform(-6, 6)  # Â±6dB
                audio = audio + volume_change
                
            else:  # severe
                # ä¸¥é‡é—®é¢˜ï¼šå¤šé‡é—®é¢˜ç»„åˆ
                
                # 1. æ·»åŠ æ›´å¤šåœé¡¿
                segments = []
                chunk_size = random.randint(600, 1000)  # è¾ƒå°çš„å—
                pause_duration = random.randint(300, 800)  # è¾ƒé•¿åœé¡¿
                
                for i in range(0, len(audio), chunk_size):
                    segments.append(audio[i:i+chunk_size])
                    # 50%æ¦‚ç‡æ·»åŠ åœé¡¿
                    if random.random() < 0.5 and i + chunk_size < len(audio):
                        segments.append(AudioSegment.silent(duration=pause_duration))
                
                audio = sum(segments) if segments else audio
                
                # 2. æç«¯è¯­é€Ÿå˜åŒ–
                extreme_speed = random.choice([0.6, 0.7, 1.4, 1.5])
                audio = audio.speedup(playback_speed=extreme_speed)
                
                # 3. å¤§å¹…éŸ³é‡å˜åŒ–
                volume_change = random.uniform(-10, 10)  # Â±10dB
                audio = audio + volume_change
            
            audio.export(output_path, format="mp3", bitrate="128k")
            
        except Exception as e:
            print(f"      é™è´¨ç¨³å®šæ€§å¤±è´¥ {input_path}: {e}")
            shutil.copy2(input_path, output_path)
    
    def degrade_overall(self, input_path: str, output_path: str):
        """ç»¼åˆé™è´¨ - å½±å“å¤šä¸ªç»´åº¦"""
        temp_wav = os.path.join(self.temp_dir, f"temp_overall_{random.randint(1000,9999)}.wav")
        
        try:
            y, sr = librosa.load(input_path, sr=16000)
            
            # 1. è½»å¾®éŸ³è°ƒé—®é¢˜
            pitch_shift = random.uniform(-2, 2)
            y = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch_shift)
            
            # 2. æ·»åŠ å™ªéŸ³
            noise_level = random.uniform(0.02, 0.06)
            noise = np.random.normal(0, noise_level, y.shape)
            y = y + noise
            
            # 3. è½»å¾®å¤±çœŸ
            distortion = random.uniform(1.1, 1.4)
            y = np.tanh(y * distortion) * 0.85
            
            # 4. ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
            y = np.clip(y, -0.95, 0.95)
            
            # ä¿å­˜ä¸ºä¸´æ—¶wav
            sf.write(temp_wav, y, sr)
            
            # è½¬æ¢ä¸ºAudioSegmentè¿›è¡Œåå¤„ç†
            audio = AudioSegment.from_wav(temp_wav)
            
            # 5. æ·»åŠ éšæœºåœé¡¿
            if random.random() < 0.6:  # 60%æ¦‚ç‡æ·»åŠ åœé¡¿
                segments = []
                chunk_size = random.randint(1000, 1500)
                pause_duration = random.randint(150, 400)
                
                for i in range(0, len(audio), chunk_size):
                    segments.append(audio[i:i+chunk_size])
                    # 25%æ¦‚ç‡æ·»åŠ åœé¡¿
                    if random.random() < 0.25 and i + chunk_size < len(audio):
                        segments.append(AudioSegment.silent(duration=pause_duration))
                
                audio = sum(segments) if segments else audio
            
            # 6. è½»å¾®éŸ³é‡è°ƒæ•´
            volume_change = random.uniform(-3, 3)
            audio = audio + volume_change
            
            audio.export(output_path, format="mp3", bitrate="128k")
            
        except Exception as e:
            print(f"      ç»¼åˆé™è´¨å¤±è´¥ {input_path}: {e}")
            shutil.copy2(input_path, output_path)
        finally:
            if os.path.exists(temp_wav):
                os.remove(temp_wav)
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)


class XunfeiComparisonExperiment:
    """ç§‘å¤§è®¯é£APIå¯¹æ¯”å®éªŒç®¡ç†å™¨"""
    
    def __init__(self):
        self.speech_evaluator = SpeechQualityEvaluator()
        self.degrader = XunfeiTargetedDegrader()
    
    def run_comprehensive_experiment(self, baseline_course_folder: str):
        """è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ"""
        
        print("ğŸ§ª å¼€å§‹ç§‘å¤§è®¯é£APIæ•æ„Ÿæ€§å¯¹æ¯”å®éªŒ")
        print("="*60)
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
        if not self._validate_course_folder(baseline_course_folder):
            return None
        
        try:
            # 1. æµ‹è¯•baseline
            print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šæµ‹è¯•é«˜è´¨é‡baseline...")
            baseline_results = self.speech_evaluator.evaluate_course_audio_simple(baseline_course_folder)
            
            if not baseline_results:
                print("âŒ Baselineè¯„æµ‹å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å®éªŒ")
                return None
            
            print(f"   âœ… Baselineè¯„æµ‹æˆåŠŸ - å¹³å‡åˆ†: {baseline_results.get('average_total_score', 0):.1f}")
            
            # 2. åˆ›å»ºå„ç»´åº¦é™è´¨æ ·æœ¬
            print("\nğŸ”§ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºé™è´¨æ ·æœ¬...")
            degraded_root = f"{baseline_course_folder}_degraded_experiment"
            
            # è®¾ç½®é™è´¨æ–‡ä»¶å¤¹ç»“æ„
            self._setup_degraded_folders(baseline_course_folder, degraded_root)
            
            # åˆ›å»ºé™è´¨éŸ³é¢‘
            audio_folder = os.path.join(baseline_course_folder, "audiosample")
            self.degrader.create_poor_samples_by_dimension(audio_folder, degraded_root)
            
            # 3. æµ‹è¯•å„ç»´åº¦é™è´¨æ•ˆæœ
            print("\nğŸ“‰ ç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•é™è´¨æ ·æœ¬...")
            dimension_results = self._test_all_dimensions(degraded_root)
            
            # 4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
            print("\nğŸ“Š ç¬¬å››æ­¥ï¼šç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
            comparison_analysis = self._analyze_results(baseline_results, dimension_results)
            
            # 5. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            self._generate_comprehensive_report(baseline_results, dimension_results, comparison_analysis)
            
            # 6. æ¸…ç†
            self.degrader.cleanup()
            
            print(f"\nğŸ‰ å®éªŒå®Œæˆï¼é™è´¨æ ·æœ¬ä¿å­˜åœ¨: {degraded_root}")
            
            return {
                'baseline': baseline_results,
                'degraded': dimension_results,
                'analysis': comparison_analysis,
                'degraded_folder': degraded_root
            }
            
        except Exception as e:
            print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            self.degrader.cleanup()
            return None
    
    def _validate_course_folder(self, course_folder: str) -> bool:
        """éªŒè¯è¯¾ç¨‹æ–‡ä»¶å¤¹ç»“æ„"""
        if not os.path.exists(course_folder):
            print(f"âŒ è¯¾ç¨‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {course_folder}")
            return False
        
        audio_folder = os.path.join(course_folder, "audiosample")
        text_folder = os.path.join(course_folder, "textsample")
        
        if not os.path.exists(audio_folder):
            print(f"âŒ ç¼ºå°‘éŸ³é¢‘æ–‡ä»¶å¤¹: {audio_folder}")
            return False
        
        if not os.path.exists(text_folder):
            print(f"âŒ ç¼ºå°‘æ–‡æœ¬æ–‡ä»¶å¤¹: {text_folder}")
            return False
        
        audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.mp3')]
        text_files = [f for f in os.listdir(text_folder) if f.endswith('.txt')]
        
        if len(audio_files) == 0:
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰MP3æ–‡ä»¶")
            return False
        
        if len(text_files) == 0:
            print(f"âŒ æ–‡æœ¬æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰TXTæ–‡ä»¶")
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶å’Œ {len(text_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        return True
    
    def _setup_degraded_folders(self, baseline_folder: str, degraded_root: str):
        """è®¾ç½®é™è´¨å®éªŒæ–‡ä»¶å¤¹ç»“æ„"""
        print("   ğŸ“ è®¾ç½®æ–‡ä»¶å¤¹ç»“æ„...")
        
        text_folder = os.path.join(baseline_folder, "textsample")
        dimensions = ['poor_fluency', 'poor_tone', 'poor_phone', 'poor_stability', 'poor_overall']
        
        for dim in dimensions:
            dim_folder = os.path.join(degraded_root, dim)
            dim_text_folder = os.path.join(dim_folder, "textsample")
            
            os.makedirs(dim_text_folder, exist_ok=True)
            
            # å¤åˆ¶æ–‡æœ¬æ–‡ä»¶
            if os.path.exists(text_folder):
                for file in os.listdir(text_folder):
                    if file.endswith('.txt'):
                        shutil.copy2(
                            os.path.join(text_folder, file),
                            os.path.join(dim_text_folder, file)
                        )
        
        print("   âœ… æ–‡ä»¶å¤¹ç»“æ„è®¾ç½®å®Œæˆ")
    
    def _test_all_dimensions(self, degraded_root: str) -> Dict:
        """æµ‹è¯•æ‰€æœ‰ç»´åº¦çš„é™è´¨æ•ˆæœ"""
        dimension_results = {}
        
        dimensions = {
            'poor_fluency': 'æµåˆ©åº¦é™è´¨',
            'poor_tone': 'å£°è°ƒé™è´¨', 
            'poor_phone': 'éŸ³ç´ é™è´¨',
            'poor_stability': 'ç¨³å®šæ€§é™è´¨',
            'poor_overall': 'ç»¼åˆé™è´¨'
        }
        
        for dim_key, dim_name in dimensions.items():
            print(f"   ğŸ” æµ‹è¯• {dim_name}...")
            dim_folder = os.path.join(degraded_root, dim_key)
            
            try:
                result = self.speech_evaluator.evaluate_course_audio_simple(dim_folder)
                dimension_results[dim_key] = result
                
                if result:
                    print(f"      âœ… å®Œæˆ - å¹³å‡åˆ†: {result.get('average_total_score', 0):.1f}")
                else:
                    print(f"      âŒ è¯„æµ‹å¤±è´¥")
                    
            except Exception as e:
                print(f"      âŒ æµ‹è¯•å¤±è´¥: {e}")
                dimension_results[dim_key] = None
        
        return dimension_results
    
    def _analyze_results(self, baseline: Dict, degraded_results: Dict) -> Dict:
        """åˆ†æå®éªŒç»“æœ"""
        analysis = {
            'changes': {},
            'sensitivity': {},
            'effectiveness': {}
        }
        
        if not baseline:
            return analysis
        
        # åˆ†æå„ç»´åº¦å˜åŒ–
        for dim, result in degraded_results.items():
            if result is None:
                continue
            
            changes = {}
            sensitivity = {}
            
            # è®¡ç®—å„æŒ‡æ ‡å˜åŒ–
            metrics = ['average_fluency', 'average_tone_accuracy', 'average_phone_accuracy', 'average_total_score']
            
            for metric in metrics:
                if metric in baseline and metric in result:
                    change = baseline[metric] - result[metric]
                    changes[metric] = change
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ˜¾è‘—å˜åŒ– (>3åˆ†ä¸ºæ˜¾è‘—)
                    sensitivity[metric] = abs(change) > 3
            
            # ç¨³å®šæ€§å˜åŒ– (æ•°å€¼è¶Šå¤§è¶Šä¸ç¨³å®š)
            if 'stability' in baseline and 'stability' in result:
                stability_change = result['stability'] - baseline['stability']
                changes['stability'] = stability_change
                sensitivity['stability'] = stability_change > 2  # æ ‡å‡†å·®å¢åŠ >2ä¸ºæ˜¾è‘—
            
            analysis['changes'][dim] = changes
            analysis['sensitivity'][dim] = sensitivity
            
            # è¯„ä¼°é™è´¨æ•ˆæœ
            significant_changes = sum(sensitivity.values())
            total_metrics = len(sensitivity)
            
            if significant_changes >= total_metrics * 0.7:
                effectiveness = 'high'
            elif significant_changes >= total_metrics * 0.4:
                effectiveness = 'medium'
            else:
                effectiveness = 'low'
            
            analysis['effectiveness'][dim] = effectiveness
        
        return analysis
    
    def _generate_comprehensive_report(self, baseline: Dict, degraded_results: Dict, analysis: Dict):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        
        print(f"\n{'='*70}")
        print("ğŸ“Š ç§‘å¤§è®¯é£APIæ•æ„Ÿæ€§æµ‹è¯• - è¯¦ç»†æŠ¥å‘Š")
        print(f"{'='*70}")
        
        if not baseline:
            print("âŒ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼šBaselineæ•°æ®ç¼ºå¤±")
            return
        
        # Baselineç»“æœ
        print(f"\nğŸ“ˆ Baselineï¼ˆé«˜è´¨é‡æ ·æœ¬ï¼‰ç»“æœ:")
        print(f"   ğŸ—£ï¸  æµåˆ©åº¦: {baseline.get('average_fluency', 0):.2f}")
        print(f"   ğŸµ å£°è°ƒå‡†ç¡®åº¦: {baseline.get('average_tone_accuracy', 0):.2f}")
        print(f"   ğŸ”¤ éŸ³ç´ å‡†ç¡®åº¦: {baseline.get('average_phone_accuracy', 0):.2f}")
        print(f"   ğŸ¯ æ€»åˆ†: {baseline.get('average_total_score', 0):.2f}")
        print(f"   ğŸ“Š ç¨³å®šæ€§: {baseline.get('stability', 0):.2f}")
        print(f"   ğŸ“‹ æ ·æœ¬æ•°: {baseline.get('sample_count', 0)}")
        
        # é™è´¨ç»“æœå¯¹æ¯”
        print(f"\nğŸ“‰ é™è´¨æ ·æœ¬æµ‹è¯•ç»“æœ:")
        
        dimension_names = {
            'poor_fluency': 'ğŸ—£ï¸  æµåˆ©åº¦é™è´¨',
            'poor_tone': 'ğŸµ å£°è°ƒé™è´¨', 
            'poor_phone': 'ğŸ”¤ éŸ³ç´ é™è´¨',
            'poor_stability': 'ğŸ“Š ç¨³å®šæ€§é™è´¨',
            'poor_overall': 'ğŸ¯ ç»¼åˆé™è´¨'
        }
        
        for dim, result in degraded_results.items():
            if result is None:
                print(f"\n{dimension_names.get(dim, dim)}: âŒ æµ‹è¯•å¤±è´¥")
                continue
            
            print(f"\n{dimension_names.get(dim, dim)}:")
            
            # æ˜¾ç¤ºå„é¡¹æŒ‡æ ‡
            metrics_display = {
                'average_fluency': 'æµåˆ©åº¦',
                'average_tone_accuracy': 'å£°è°ƒ',
                'average_phone_accuracy': 'éŸ³ç´ ', 
                'average_total_score': 'æ€»åˆ†',
                'stability': 'ç¨³å®šæ€§'
            }
            
            for metric, display_name in metrics_display.items():
                if metric in result:
                    value = result[metric]
                    baseline_value = baseline.get(metric, 0)
                    
                    if metric == 'stability':
                        change = value - baseline_value
                        direction = "â†—ï¸" if change > 0 else "â†˜ï¸" if change < 0 else "â†’"
                        print(f"   {display_name}: {value:.2f} {direction} (å˜åŒ–: {change:+.2f})")
                    else:
                        change = baseline_value - value
                        direction = "â†˜ï¸" if change > 0 else "â†—ï¸" if change < 0 else "â†’"
                        print(f"   {display_name}: {value:.2f} {direction} (ä¸‹é™: {change:.2f})")
            
            # æ˜¾ç¤ºæ•ˆæœè¯„ä¼°
            effectiveness = analysis.get('effectiveness', {}).get(dim, 'unknown')
            effectiveness_symbols = {
                'high': 'ğŸ”´ é«˜æ•ˆæœ',
                'medium': 'ğŸŸ¡ ä¸­ç­‰æ•ˆæœ', 
                'low': 'ğŸŸ¢ ä½æ•ˆæœ',
                'unknown': 'â“ æœªçŸ¥'
            }
            print(f"   é™è´¨æ•ˆæœ: {effectiveness_symbols.get(effectiveness, effectiveness)}")
        
        # APIæ•æ„Ÿæ€§åˆ†æ
        print(f"\nğŸ¯ APIæ•æ„Ÿæ€§åˆ†æ:")
        
        sensitivity_summary = {}
        for dim, sensitivity_data in analysis.get('sensitivity', {}).items():
            sensitive_count = sum(sensitivity_data.values())
            total_metrics = len(sensitivity_data)
            sensitivity_ratio = sensitive_count / total_metrics if total_metrics > 0 else 0
            sensitivity_summary[dim] = sensitivity_ratio
        
        for dim, ratio in sensitivity_summary.items():
            dim_name = dimension_names.get(dim, dim)
            if ratio >= 0.7:
                level = "ğŸ”´ é«˜æ•æ„Ÿ"
                desc = "APIèƒ½å¾ˆå¥½åœ°æ£€æµ‹æ­¤ç±»é—®é¢˜"
            elif ratio >= 0.4:
                level = "ğŸŸ¡ ä¸­æ•æ„Ÿ"
                desc = "APIèƒ½éƒ¨åˆ†æ£€æµ‹æ­¤ç±»é—®é¢˜"
            else:
                level = "ğŸŸ¢ ä½æ•æ„Ÿ"
                desc = "APIå¯¹æ­¤ç±»é—®é¢˜ä¸å¤Ÿæ•æ„Ÿ"
            
            print(f"   {dim_name}: {level} ({ratio:.1%}) - {desc}")
        
        # æ€»ä½“è¯„ä¼°
        print(f"\nğŸ† æ€»ä½“è¯„ä¼°:")
        
        avg_sensitivity = statistics.mean(sensitivity_summary.values()) if sensitivity_summary else 0
        
        if avg_sensitivity >= 0.7:
            overall_rating = "ğŸŒŸ ä¼˜ç§€"
            recommendation = "ç§‘å¤§è®¯é£APIå…·æœ‰å¾ˆå¼ºçš„åŒºåˆ†èƒ½åŠ›ï¼Œé€‚åˆç”¨äºæ•™å­¦è´¨é‡è¯„ä¼°"
        elif avg_sensitivity >= 0.5:
            overall_rating = "ğŸ‘ è‰¯å¥½"
            recommendation = "ç§‘å¤§è®¯é£APIå…·æœ‰è¾ƒå¥½çš„åŒºåˆ†èƒ½åŠ›ï¼Œå¯ä»¥ç”¨äºæ•™å­¦è´¨é‡è¯„ä¼°"
        elif avg_sensitivity >= 0.3:
            overall_rating = "ğŸ¤” ä¸€èˆ¬"
            recommendation = "ç§‘å¤§è®¯é£APIçš„åŒºåˆ†èƒ½åŠ›ä¸­ç­‰ï¼Œéœ€è¦ç»“åˆå…¶ä»–æŒ‡æ ‡ä½¿ç”¨"
        else:
            overall_rating = "âš ï¸ è¾ƒå¼±"
            recommendation = "ç§‘å¤§è®¯é£APIçš„åŒºåˆ†èƒ½åŠ›è¾ƒå¼±ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨"
        
        print(f"   APIåŒºåˆ†èƒ½åŠ›: {overall_rating} (å¹³å‡æ•æ„Ÿæ€§: {avg_sensitivity:.1%})")
        print(f"   ä½¿ç”¨å»ºè®®: {recommendation}")
        
        # æœ€æœ‰æ•ˆçš„é™è´¨æ–¹æ³•
        if analysis.get('effectiveness'):
            most_effective = max(analysis['effectiveness'].items(), key=lambda x: x[1] if x[1] != 'unknown' else '')
            if most_effective[1] != 'unknown':
                print(f"   æœ€æœ‰æ•ˆé™è´¨æ–¹æ³•: {dimension_names.get(most_effective[0], most_effective[0])}")
        
        print("="*70)
        print("âœ… å®éªŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ")


def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´å®éªŒ"""
    
    print("ğŸ“ ç§‘å¤§è®¯é£è¯­éŸ³è¯„æµ‹APIæ•æ„Ÿæ€§éªŒè¯å®éªŒ")
    print("="*50)
    
    # è¯·ä¿®æ”¹æ­¤è·¯å¾„ä¸ºä½ çš„é«˜è´¨é‡è¯¾ç¨‹æ–‡ä»¶å¤¹è·¯å¾„
    # æ–‡ä»¶å¤¹åº”åŒ…å« audiosample/ å’Œ textsample/ å­æ–‡ä»¶å¤¹
    baseline_course_folder = "/Users/zhangshenao/Desktop/research/äº¤å¤§æ•™è‚²å¤§æ¨¡å‹æµ‹è¯„/eval/Resources/sample/1"
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(baseline_course_folder):
        print(f"âŒ è¯·ä¿®æ”¹ baseline_course_folder è·¯å¾„")
        print(f"   å½“å‰è·¯å¾„: {baseline_course_folder}")
        print(f"   è¯¥è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·è®¾ç½®ä¸ºä½ çš„å®é™…è¯¾ç¨‹æ–‡ä»¶å¤¹è·¯å¾„")
        return
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment = XunfeiComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å®éªŒ
    try:
        results = experiment.run_comprehensive_experiment(baseline_course_folder)
        
        if results:
            print(f"\nğŸ‰ å®éªŒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜ä½ç½®: {results.get('degraded_folder', 'N/A')}")
            
            # å¯é€‰ï¼šä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            import json
            result_file = f"{baseline_course_folder}_experiment_results.json"
            
            # å‡†å¤‡å¯åºåˆ—åŒ–çš„ç»“æœ
            serializable_results = {
                'baseline': results['baseline'],
                'degraded_summary': {k: v for k, v in results['degraded'].items() if v is not None},
                'analysis_summary': results['analysis']
            }
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
            
        else:
            print("âŒ å®éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()